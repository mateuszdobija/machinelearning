{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Exercises\n",
    "\n",
    "We have five exercises in this section. The exercises are:\n",
    "1. Build your own tokenizer, where you need to implement two functions to implement a tokenizer based on regular expression.\n",
    "2. Get tags from Trump speech.\n",
    "3. Get the nouns in the last 10 sentences from Trump's speech and find the nouns divided by sentencens. Use SpaCy.\n",
    "4. Build your own Bag Of Words implementation using tokenizer created before.\n",
    "5. Build a 5-gram model and clean up the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1. Build your own tokenizer\n",
    "\n",
    "Build two different tokenizers:\n",
    "- ``tokenize_sentence``: function tokenizing text into sentences,\n",
    "- ``tokenize_word``: function tokenizing text into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentences:\n",
      "['Here we go again.', \"I was supposed to add this text later.Well, it's 10.p.m. here, and I'm actually having fun making this course.\", ':oI hope you are getting along fine with this presentation, I really did try.And one last sentence, just so you can test you tokenizers better.']\n",
      "Tokenized words:\n",
      "['Here', 'we', 'go', 'again.', 'I', 'was', 'supposed', 'to', 'add', 'this', 'text', 'later.Well,', \"it's\", '10.p.m.', 'here,', 'and', \"I'm\", 'actually', 'having', 'fun', 'making', 'this', 'course.', ':oI', 'hope', 'you', 'are', 'getting', 'along', 'fine', 'with', 'this', 'presentation,', 'I', 'really', 'did', 'try.And', 'one', 'last', 'sentence,', 'just', 'so', 'you', 'can', 'test', 'you', 'tokenizers', 'better.']\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import  re\n",
    "\n",
    "def tokenize_words(text: str) -> list:\n",
    "    \"\"\"Tokenize text into words using regex.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "            Text to be tokenized\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "            List containing words tokenized from text\n",
    "\n",
    "    \"\"\"\n",
    "    words = re.split(' ',text)\n",
    "    return words\n",
    "\n",
    "def tokenize_sentence(text: str) -> list:\n",
    "    \"\"\"Tokenize text into words using regex.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "            Text to be tokenized\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "            List containing words tokenized from text\n",
    "\n",
    "    \"\"\"\n",
    "    rgx = re.compile(\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s\")\n",
    "    sentences = rgx.split(text)\n",
    "    return sentences\n",
    "\n",
    "    \n",
    "\n",
    "text = \"Here we go again. I was supposed to add this text later.\\\n",
    "Well, it's 10.p.m. here, and I'm actually having fun making this course. :o\\\n",
    "I hope you are getting along fine with this presentation, I really did try.\\\n",
    "And one last sentence, just so you can test you tokenizers better.\"\n",
    "\n",
    "print(\"Tokenized sentences:\")\n",
    "print(tokenize_sentence(text))\n",
    "\n",
    "print(\"Tokenized words:\")\n",
    "print(tokenize_words(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2. Get tags from Trump speech using NLTK\n",
    "\n",
    "You should use the ``trump.txt`` file, read it and find the tags for each word. Use NLTK for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mateusz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/mateusz/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " (',', ','),\n",
       " ('everybody', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('Thank', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('very', 'RB'),\n",
       " ('much', 'RB'),\n",
       " ('.', '.'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " (',', ','),\n",
       " ('Matt', 'NNP'),\n",
       " (',', ','),\n",
       " ('for', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('introduction', 'NN'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('thank', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('for', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('big', 'JJ'),\n",
       " ('crowd', 'NN'),\n",
       " ('.', '.'),\n",
       " ('This', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('incredible', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Really', 'RB'),\n",
       " ('incredible', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('all', 'DT'),\n",
       " ('come', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('long', 'JJ'),\n",
       " ('way', 'NN'),\n",
       " ('together', 'RB'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('come', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('long', 'JJ'),\n",
       " ('way', 'NN'),\n",
       " ('together', 'RB'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('m', 'RB'),\n",
       " ('thrilled', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('back', 'RB'),\n",
       " ('at', 'IN'),\n",
       " ('CPAC', 'NNP'),\n",
       " (',', ','),\n",
       " ('with', 'IN'),\n",
       " ('so', 'RB'),\n",
       " ('many', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('wonderful', 'JJ'),\n",
       " ('friends', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('amazing', 'JJ'),\n",
       " ('supporters', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('proud', 'JJ'),\n",
       " ('conservatives', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Remember', 'NNP'),\n",
       " ('when', 'WRB'),\n",
       " ('I', 'PRP'),\n",
       " ('first', 'RB'),\n",
       " ('started', 'VBD'),\n",
       " ('running', 'VBG'),\n",
       " ('?', '.'),\n",
       " ('Because', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('wasn', 'VBP'),\n",
       " ('’', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('politician', 'NN'),\n",
       " (',', ','),\n",
       " ('fortunately', 'RB'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('do', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('remember', 'VB'),\n",
       " ('I', 'PRP'),\n",
       " ('started', 'VBD'),\n",
       " ('running', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('people', 'NNS'),\n",
       " ('said', 'VBD'),\n",
       " (',', ','),\n",
       " ('are', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('sure', 'JJ'),\n",
       " ('he', 'PRP'),\n",
       " ('’', 'VBZ'),\n",
       " ('s', 'PDT'),\n",
       " ('a', 'DT'),\n",
       " ('conservative', 'JJ'),\n",
       " ('?', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('think', 'VBP'),\n",
       " ('I', 'PRP'),\n",
       " ('proved', 'VBD'),\n",
       " ('I', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('m', 'PDT'),\n",
       " ('a', 'DT'),\n",
       " ('conservative', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('For', 'IN'),\n",
       " ('more', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('four', 'CD'),\n",
       " ('decades', 'NNS'),\n",
       " (',', ','),\n",
       " ('this', 'DT'),\n",
       " ('event', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('served', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('forum', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('nation', 'NN'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('top', 'JJ'),\n",
       " ('leaders', 'NNS'),\n",
       " (',', ','),\n",
       " ('activists', 'NNS'),\n",
       " (',', ','),\n",
       " ('writers', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('thinkers', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Year', 'NN'),\n",
       " ('after', 'IN'),\n",
       " ('year', 'NN'),\n",
       " (',', ','),\n",
       " ('leaders', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('stood', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('stage', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('discuss', 'VB'),\n",
       " ('what', 'WP'),\n",
       " ('we', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('do', 'VB'),\n",
       " ('together', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('protect', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('heritage', 'NN'),\n",
       " (',', ','),\n",
       " ('to', 'TO'),\n",
       " ('promote', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('culture', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('to', 'TO'),\n",
       " ('defend', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('freedom', 'NN'),\n",
       " ('.', '.'),\n",
       " ('CPAC', 'NNP'),\n",
       " ('has', 'VBZ'),\n",
       " ('always', 'RB'),\n",
       " ('been', 'VBN'),\n",
       " ('about', 'RB'),\n",
       " ('big', 'JJ'),\n",
       " ('ideas', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('also', 'RB'),\n",
       " ('been', 'VBN'),\n",
       " ('about', 'IN'),\n",
       " ('putting', 'VBG'),\n",
       " ('those', 'DT'),\n",
       " ('ideas', 'NNS'),\n",
       " ('into', 'IN'),\n",
       " ('action', 'NN'),\n",
       " ('—', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('CPAC', 'NNP'),\n",
       " ('really', 'RB'),\n",
       " ('has', 'VBZ'),\n",
       " ('put', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('ideas', 'NNS'),\n",
       " ('into', 'IN'),\n",
       " ('action', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('ll', 'JJ'),\n",
       " ('talk', 'NN'),\n",
       " ('about', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('them', 'PRP'),\n",
       " ('this', 'DT'),\n",
       " ('morning', 'NN'),\n",
       " ('.', '.'),\n",
       " ('For', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('last', 'JJ'),\n",
       " ('year', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('help', 'NN'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('put', 'VBN'),\n",
       " ('more', 'JJR'),\n",
       " ('great', 'JJ'),\n",
       " ('conservative', 'JJ'),\n",
       " ('ideas', 'NNS'),\n",
       " ('into', 'IN'),\n",
       " ('use', 'NN'),\n",
       " ('than', 'IN'),\n",
       " ('perhaps', 'RB'),\n",
       " ('ever', 'RB'),\n",
       " ('before', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('American', 'JJ'),\n",
       " ('history', 'NN'),\n",
       " ('.', '.'),\n",
       " ('What', 'WP'),\n",
       " ('a', 'DT'),\n",
       " ('nice', 'JJ'),\n",
       " ('picture', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('.', '.'),\n",
       " ('Look', 'VB'),\n",
       " ('at', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('love', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('watch', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('guy', 'NN'),\n",
       " ('speak', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Oh', 'UH'),\n",
       " (',', ','),\n",
       " ('boy', 'UH'),\n",
       " ('.', '.'),\n",
       " ('Oh', 'UH'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('try', 'VBP'),\n",
       " ('like', 'IN'),\n",
       " ('hell', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('hide', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('bald', 'NN'),\n",
       " ('spot', 'NN'),\n",
       " (',', ','),\n",
       " ('folks', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('work', 'VBP'),\n",
       " ('hard', 'RB'),\n",
       " ('at', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('Doesn', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('t', 'VBD'),\n",
       " ('look', 'NN'),\n",
       " ('bad', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Hey', 'NNP'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'JJ'),\n",
       " ('hanging', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'JJ'),\n",
       " ('hanging', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'JJ'),\n",
       " ('hanging', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('there', 'RB'),\n",
       " (',', ','),\n",
       " ('right', 'RB'),\n",
       " ('?', '.'),\n",
       " ('Together', 'RB'),\n",
       " ('we', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'JJ'),\n",
       " ('hanging', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('confirmed', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('record', 'NN'),\n",
       " ('number', 'NN'),\n",
       " (',', ','),\n",
       " ('so', 'RB'),\n",
       " ('important', 'JJ'),\n",
       " (',', ','),\n",
       " ('of', 'IN'),\n",
       " ('circuit', 'NN'),\n",
       " ('court', 'NN'),\n",
       " ('judges', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'RB'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('putting', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('more', 'JJR'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('they', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('interpret', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('law', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('written', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('confirmed', 'VBN'),\n",
       " ('an', 'DT'),\n",
       " ('incredible', 'JJ'),\n",
       " ('new', 'JJ'),\n",
       " ('Supreme', 'NNP'),\n",
       " ('Court', 'NNP'),\n",
       " ('justice', 'NN'),\n",
       " (',', ','),\n",
       " ('a', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('man', 'NN'),\n",
       " (',', ','),\n",
       " ('Neil', 'NNP'),\n",
       " ('Gorsuch', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Right', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('passed', 'VBN'),\n",
       " ('massive', 'JJ'),\n",
       " (',', ','),\n",
       " ('biggest', 'JJS'),\n",
       " ('in', 'IN'),\n",
       " ('history', 'NN'),\n",
       " (',', ','),\n",
       " ('tax', 'NN'),\n",
       " ('cuts', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('reforms', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('don', 'VBP'),\n",
       " ('’', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " ('use', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('word', 'NN'),\n",
       " ('reform', 'NN'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('was', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('reform', 'NN'),\n",
       " ('too', 'RB'),\n",
       " (',', ','),\n",
       " ('very', 'RB'),\n",
       " ('positive', 'JJ'),\n",
       " ('—', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('don', 'VBP'),\n",
       " ('’', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " ('use', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('when', 'WRB'),\n",
       " ('we', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('first', 'RB'),\n",
       " ('doing', 'VBG'),\n",
       " ('it', 'PRP'),\n",
       " ('I', 'PRP'),\n",
       " ('told', 'VBD'),\n",
       " ('everybody', 'NN'),\n",
       " (',', ','),\n",
       " ('everybody', 'NN'),\n",
       " ('gathered', 'VBD'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " (',', ','),\n",
       " ('just', 'RB'),\n",
       " ('talk', 'VB'),\n",
       " ('about', 'IN'),\n",
       " ('tax', 'NN'),\n",
       " ('cuts', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('People', 'NNS'),\n",
       " ('don', 'VBP'),\n",
       " ('’', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " ('know', 'VBP'),\n",
       " ('what', 'WP'),\n",
       " ('reform', 'NN'),\n",
       " ('means', 'VBZ'),\n",
       " ('.', '.'),\n",
       " ('They', 'PRP'),\n",
       " ('think', 'VBP'),\n",
       " ('reform', 'NN'),\n",
       " ('might', 'MD'),\n",
       " ('mean', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('going', 'VBG'),\n",
       " ('up', 'RP'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " (',', ','),\n",
       " ('do', 'VBP'),\n",
       " ('tax', 'NN'),\n",
       " ('cuts', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('How', 'WRB'),\n",
       " ('did', 'VBD'),\n",
       " ('he', 'PRP'),\n",
       " ('get', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('here', 'RB'),\n",
       " (',', ','),\n",
       " ('Matt', 'NNP'),\n",
       " ('?', '.'),\n",
       " ('Boy', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Okay', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Just', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('media', 'NNS'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('fake', 'JJ'),\n",
       " ('news', 'NN'),\n",
       " ('back', 'RB'),\n",
       " ('there', 'RB'),\n",
       " (',', ','),\n",
       " ('they', 'PRP'),\n",
       " ('took', 'VBD'),\n",
       " ('very', 'RB'),\n",
       " ('good', 'JJ'),\n",
       " ('care', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('him', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('They', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('very', 'RB'),\n",
       " ('gentle', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('He', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('very', 'RB'),\n",
       " ('obnoxious', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('only', 'RB'),\n",
       " ('one', 'CD'),\n",
       " ('person', 'NN'),\n",
       " ('.', '.'),\n",
       " ('So', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('thousands', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('people', 'NNS'),\n",
       " ('here', 'RB'),\n",
       " ('.', '.'),\n",
       " ('So', 'RB'),\n",
       " (',', ','),\n",
       " ('listen', 'UH'),\n",
       " (',', ','),\n",
       " ('tomorrow', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('headline', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('protesters', 'NNS'),\n",
       " ('disturb', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('Trump', 'NNP'),\n",
       " ('—', 'NNP'),\n",
       " ('one', 'CD'),\n",
       " ('person', 'NN'),\n",
       " (',', ','),\n",
       " ('folks', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Doesn', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('deserve', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('mention', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Doesn', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('deserve', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('headline', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('headline', 'NN'),\n",
       " ('tomorrow', 'NN'),\n",
       " (',', ','),\n",
       " ('disrupters', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('CPAC', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('One', 'CD'),\n",
       " ('person', 'NN'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('he', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('very', 'RB'),\n",
       " ('nice', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('looked', 'VBD'),\n",
       " ('at', 'IN'),\n",
       " ('him', 'PRP'),\n",
       " (',', ','),\n",
       " ('he', 'PRP'),\n",
       " ('immediately', 'RB'),\n",
       " ('left', 'VBD'),\n",
       " ('.', '.'),\n",
       " ('Okay', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Now', 'RB'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('ve', 'RB'),\n",
       " ('heard', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('too', 'RB'),\n",
       " ('often', 'RB'),\n",
       " ('.', '.'),\n",
       " ('You', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('ll', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('one', 'CD'),\n",
       " ('person', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('you', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('hardly', 'RB'),\n",
       " ('even', 'RB'),\n",
       " ('hear', 'VBP'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('biggest', 'JJS'),\n",
       " ('disturbance', 'NN'),\n",
       " ('are', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('people', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('You', 'PRP'),\n",
       " ('know', 'VBP'),\n",
       " ('why', 'WRB'),\n",
       " ('?', '.'),\n",
       " ('He', 'PRP'),\n",
       " ('’', 'VBZ'),\n",
       " ('ll', 'NNS'),\n",
       " ('say', 'VBP'),\n",
       " ('something', 'NN'),\n",
       " (',', ','),\n",
       " ('nobody', 'NN'),\n",
       " ('hears', 'VBZ'),\n",
       " ('him', 'PRP'),\n",
       " (',', ','),\n",
       " ('because', 'IN'),\n",
       " ('—', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('then', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('crowd', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('start', 'VB'),\n",
       " ('screaming', 'VBG'),\n",
       " ('at', 'IN'),\n",
       " ('him', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('then', 'RB'),\n",
       " ('all', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('sudden', 'JJ'),\n",
       " ('we', 'PRP'),\n",
       " ('start', 'VBP'),\n",
       " ('—', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('that', 'DT'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('okay', 'RP'),\n",
       " ('.', '.'),\n",
       " ('You', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('show', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('spirit', 'NN'),\n",
       " (',', ','),\n",
       " ('right', 'RB'),\n",
       " ('?', '.'),\n",
       " ('You', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('show', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('spirit', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('true', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('So', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('passed', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('biggest', 'JJS'),\n",
       " ('tax', 'NN'),\n",
       " ('cuts', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('history', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('country', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('called', 'VBN'),\n",
       " ('tax', 'NN'),\n",
       " ('cut', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('reform', 'NN'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('our', 'PRP$'),\n",
       " ('people', 'NNS'),\n",
       " (',', ','),\n",
       " ('don', 'JJ'),\n",
       " ('’', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('use', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('word', 'NN'),\n",
       " ('reform', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Because', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'RB'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('go', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('tax', 'NN'),\n",
       " ('reform', 'NN'),\n",
       " ('act', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " ('no', 'DT'),\n",
       " ('wonder', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('45', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('nothing', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('passed', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('Because', 'IN'),\n",
       " ('people', 'NNS'),\n",
       " ('want', 'VBP'),\n",
       " ('tax', 'NN'),\n",
       " ('cuts', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('they', 'PRP'),\n",
       " ('don', 'VBP'),\n",
       " ('’', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " ('know', 'VBP'),\n",
       " ('what', 'WP'),\n",
       " ('reform', 'NN'),\n",
       " ('means', 'VBZ'),\n",
       " ('.', '.'),\n",
       " ('Reform', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('mean', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'VB'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('pay', 'VB'),\n",
       " ('more', 'JJR'),\n",
       " ('tax', 'NN'),\n",
       " ('.', '.'),\n",
       " ('So', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('convinced', 'VBP'),\n",
       " ('politicians', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('have', 'VBP'),\n",
       " ('done', 'VBN'),\n",
       " ('this', 'DT'),\n",
       " ('all', 'DT'),\n",
       " ('their', 'PRP$'),\n",
       " ('lives', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('they', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('job', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('many', 'JJ'),\n",
       " ('cases', 'NNS'),\n",
       " (',', ','),\n",
       " ('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('—', 'PDT'),\n",
       " ('the', 'DT'),\n",
       " ('tax', 'NN'),\n",
       " ('reform', 'NN'),\n",
       " ('act', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('whatever', 'WDT'),\n",
       " ('year', 'NN'),\n",
       " ('we', 'PRP'),\n",
       " ('want', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('put', 'VB'),\n",
       " (',', ','),\n",
       " ('okay', 'NN'),\n",
       " ('.', '.'),\n",
       " ('So', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('tax', 'NN'),\n",
       " ('reform', 'NN'),\n",
       " ('act', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('that', 'DT'),\n",
       " ('was', 'VBD'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('called', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('tax', 'NN'),\n",
       " ('act', 'NN'),\n",
       " ('tax', 'NN'),\n",
       " ('cut', 'NN'),\n",
       " ('act', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('jobs', 'NNS'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('add', 'VB'),\n",
       " ('jobs', 'NNS'),\n",
       " ('into', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " (',', ','),\n",
       " ('because', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('re', 'NNS'),\n",
       " ('picking', 'VBG'),\n",
       " ('up', 'RP'),\n",
       " ('a', 'DT'),\n",
       " ('tremendous', 'JJ'),\n",
       " ('number', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('jobs', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('2.7', 'CD'),\n",
       " ('million', 'CD'),\n",
       " ('jobs', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('2.7', 'CD'),\n",
       " ('.', '.'),\n",
       " ('So', 'RB'),\n",
       " ('now', 'RB'),\n",
       " ('people', 'NNS'),\n",
       " ('hear', 'VBP'),\n",
       " ('tax', 'NN'),\n",
       " ('cuts', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('popular', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Remember', 'NNP'),\n",
       " (',', ','),\n",
       " ('it', 'PRP'),\n",
       " ('started', 'VBD'),\n",
       " ('off', 'RP'),\n",
       " ('a', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('slow', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Then', 'RB'),\n",
       " ('it', 'PRP'),\n",
       " ('got', 'VBD'),\n",
       " ('passed', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('some', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('help', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('say', 'VB'),\n",
       " ('we', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('some', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('help', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Senate', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('House', 'NNP'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('guys', 'VBN'),\n",
       " ('here', 'RB'),\n",
       " ('today', 'NN'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Congressmen', 'NNP'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('senators', 'NNS'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('help', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('got', 'VBD'),\n",
       " ('it', 'PRP'),\n",
       " ('passed', 'VBD'),\n",
       " (',', ','),\n",
       " ('just', 'RB'),\n",
       " ('—', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('easy', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('didn', 'VBP'),\n",
       " ('’', 'JJ'),\n",
       " ('t', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('one', 'CD'),\n",
       " ('Democrat', 'NNP'),\n",
       " ('vote', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('think', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('’', 'VBP'),\n",
       " ('s', 'VB'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('cost', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('midterms', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('know', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('whoever', 'WP'),\n",
       " ('wins', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('presidency', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('disadvantage', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('whatever', 'WDT'),\n",
       " ('reason', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('midterms', 'NNS'),\n",
       " ('.', '.'),\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "file = open(\"./datasets/trump.txt\", \"r\",encoding=\"utf-8\") \n",
    "trump = file.read()\n",
    "words = nltk.word_tokenize(trump)\n",
    "\n",
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3. Get the nouns in the last 10 sentences from Trump's speech and find the nouns divided by sentencens. Use SpaCy.\n",
    "\n",
    "Please use Python list features to get the last 10 sentences and display nouns from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Hopefully something positive can happen.\n",
      "Nouns:\n",
      ">>something\n",
      "> But that just was announced and I wanted to let you know.\n",
      "Nouns:\n",
      ">>I\n",
      ">>you\n",
      "> We have imposed the heaviest sanctions ever imposed.\n",
      "Nouns:\n",
      ">>We\n",
      ">>the heaviest sanctions\n",
      "> So ladies and gentlemen, thank you for everything.\n",
      "Nouns:\n",
      ">>ladies\n",
      ">>gentlemen\n",
      ">>you\n",
      ">>everything\n",
      "> You’ve been incredible partners.\n",
      "Nouns:\n",
      ">>You\n",
      ">>incredible partners\n",
      "> Incredible partners.\n",
      "Nouns:\n",
      ">>Incredible partners\n",
      "> And I will let you know in the absolute strongest of terms, we’re going to make America great again\n",
      "Nouns:\n",
      ">>I\n",
      ">>you\n",
      ">>terms\n",
      ">>we\n",
      ">>America\n",
      "> and I will never, ever, ever let you down.\n",
      "Nouns:\n",
      ">>I\n",
      ">>you\n",
      "> Thank you very much.\n",
      "Nouns:\n",
      ">>you\n",
      "> Thank you.\n",
      "\n",
      "Nouns:\n",
      ">>you\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "file = open(\"./datasets/trump.txt\", \"r\",encoding='utf-8') \n",
    "trump = file.read() \n",
    "\n",
    "### here comes your code\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "document = nlp(trump)\n",
    "sentences = list(document.sents)[-10:]\n",
    "for sentence in sentences:\n",
    "    print(\"> \"+str(sentence))\n",
    "    print(\"Nouns:\")\n",
    "    for noun in sentence.noun_chunks:\n",
    "        print(\">>\" + str(noun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4. Build your own Bag Of Words implementation using tokenizer created before \n",
    "\n",
    "You need to implement following methods:\n",
    "\n",
    "- ``fit_transform`` - gets a list of strings and returns matrix with it's BoW representation\n",
    "- ``get_features_names`` - returns list of words corresponding to columns in BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "class BagOfWords:\n",
    "    \"\"\"Basic BoW implementation.\"\"\"\n",
    "    \n",
    "    __nlp = spacy.load(\"en_core_web_sm\")\n",
    "    __bow_list = []\n",
    "    \n",
    "    # your code goes maybe also here    \n",
    "    \n",
    "    def fit_transform(self, corpus: list):\n",
    "        \"\"\"Transform list of strings into BoW array.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        corpus: List[str]\n",
    "                Corpus of texts to be transforrmed\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "                Matrix representation of BoW\n",
    "\n",
    "        \"\"\"\n",
    "        for article in corpus:\n",
    "            for sentence in tokenize_sentence(article):\n",
    "                words = tokenize_words(sentence.replace('.', ' ').replace(',', ' '))\n",
    "                for word in words:\n",
    "                    word = word.lower()\n",
    "                    if word != '' and word not in self.__bow_list:\n",
    "                        self.__bow_list.append(word)\n",
    "        BOW=[]                \n",
    "        for article in corpus:\n",
    "            _bow = []\n",
    "            for word in self.__bow_list:\n",
    "                _bow.append( len([w for w in article.split() if w.lower() == word]) )\n",
    "            BOW.append(_bow)\n",
    "        return BOW\n",
    "      \n",
    "\n",
    "    def get_feature_names(self) -> list:\n",
    "        \"\"\"Return words corresponding to columns of matrix.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List[str]\n",
    "                Words being transformed by fit function\n",
    "\n",
    "        \"\"\"   \n",
    "        # your code goes here\n",
    "        return self.__bow_list\n",
    "\n",
    "corpus = [\n",
    "     'Bag Of Words is based on counting',\n",
    "     'words occurences throughout multiple documents.',\n",
    "     'This is the third document.',\n",
    "     'As you can see most of the words occur only once.',\n",
    "     'This gives us a pretty sparse matrix, see below. Really, see below',\n",
    "]    \n",
    "    \n",
    "vectorizer = BagOfWords()\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X)\n",
    "\n",
    "vectorizer.get_feature_names()\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5. Build a 5-gram model and clean up the results.\n",
    "\n",
    "There are three tasks to do:\n",
    "1. Use 5-gram model instead of 3.\n",
    "2. Change to capital letter each first letter of a sentence.\n",
    "3. Remove the whitespace between the last word in a sentence and . ! or ?.\n",
    "\n",
    "Hint: for 2. and 3. implement a function called ``clean_generated()`` that takes the generated text and fix both issues at once. It could be easier to fix the text after it's generated rather then doing some changes in the while loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /home/mateusz/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package genesis to /home/mateusz/nltk_data...\n",
      "[nltk_data]   Package genesis is already up-to-date!\n",
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     /home/mateusz/nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n",
      "[nltk_data] Downloading package nps_chat to /home/mateusz/nltk_data...\n",
      "[nltk_data]   Package nps_chat is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to /home/mateusz/nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to /home/mateusz/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "nltk.download('gutenberg')\n",
    "nltk.download('genesis')\n",
    "nltk.download('inaugural')\n",
    "nltk.download('nps_chat')\n",
    "nltk.download('webtext')\n",
    "nltk.download('treebank')\n",
    "\n",
    "\n",
    "from nltk.book import *\n",
    "\n",
    "\n",
    "wall_street = text7.tokens\n",
    "\n",
    "import re\n",
    "\n",
    "tokens = wall_street\n",
    "\n",
    "def cleanup():\n",
    "    compiled_pattern = re.compile(\"^[a-zA-Z0-9.!?]\")\n",
    "    clean = list(filter(compiled_pattern.match,tokens))\n",
    "    return clean\n",
    "tokens = cleanup()\n",
    "\n",
    "def build_ngrams():\n",
    "    ngrams = []\n",
    "    for i in range(len(tokens)-N+1):\n",
    "        ngrams.append(tokens[i:i+N])\n",
    "    return ngrams\n",
    "\n",
    "def ngram_freqs(ngrams):\n",
    "    counts = {}\n",
    "\n",
    "    for ngram in ngrams:\n",
    "        token_seq  = SEP.join(ngram[:-1])\n",
    "        last_token = ngram[-1]\n",
    "\n",
    "        if token_seq not in counts:\n",
    "            counts[token_seq] = {}\n",
    "\n",
    "        if last_token not in counts[token_seq]:\n",
    "            counts[token_seq][last_token] = 0\n",
    "\n",
    "        counts[token_seq][last_token] += 1;\n",
    "\n",
    "    return counts\n",
    "\n",
    "def next_word(text, N, counts):\n",
    "\n",
    "    token_seq = SEP.join(text.split()[-(N-1):]);\n",
    "    choices = counts[token_seq].items();\n",
    "\n",
    "    total = sum(weight for choice, weight in choices)\n",
    "    r = random.uniform(0, total)\n",
    "    upto = 0\n",
    "    for choice, weight in choices:\n",
    "        upto += weight;\n",
    "        if upto > r: return choice\n",
    "    assert False # should not reach here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase out its oldest capacity and make appropriate reductions in operating expenses . The 35.7 million net loss equals 86 cents a share . A spokesman for Temple estimated that Sea Containers plan if all the asset sales materialize would result in shareholders receiving only 36 to 45 a share in cash . The lower figures the spokesman said 0 would stem from preferred shares being converted to common stock and the possibility that Sea Containers subsidiaries might be required to place their shares in the open market . Temple added that Sea Containers is still mired in legal problems in Bermuda where the Supreme Court has temporarily barred Sea Containers from buying back its own stock in a case brought by Stena and Tiphook .\n",
      "\n",
      "Phase out its oldest capacity and make appropriate reductions in operating expenses. The 35. 7 million net loss equals 86 cents a share. A spokesman for Temple estimated that Sea Containers plan if all the asset sales materialize would result in shareholders receiving only 36 to 45 a share in cash. The lower figures the spokesman said 0 would stem from preferred shares being converted to common stock and the possibility that Sea Containers subsidiaries might be required to place their shares in the open market. Temple added that Sea Containers is still mired in legal problems in Bermuda where the Supreme Court has temporarily barred Sea Containers from buying back its own stock in a case brought by Stena and Tiphook.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def clean_generated(text):\n",
    "    cleaned = ''\n",
    "    for sentence in text.split('.'):\n",
    "        if len(sentence) == 0:\n",
    "            continue\n",
    "        if len(sentence) == 1:\n",
    "            cleaned = sentence + '. '\n",
    "            continue\n",
    "            \n",
    "        while sentence[0] == ' ':\n",
    "            sentence = sentence[1:]\n",
    "        cleaned += sentence[0].upper()\n",
    "        \n",
    "        if sentence[-1] == '?' or sentence[-1] == '!':\n",
    "            cleaned += sentence[1:-2]\n",
    "            cleaned += sentence[-1] + ' '\n",
    "            continue\n",
    "            \n",
    "        cleaned += sentence[1:-1]\n",
    "        if sentence[-1] != ' ':\n",
    "            cleaned += sentence[-1]\n",
    "        cleaned += '. '\n",
    "        \n",
    "    return cleaned[:-1]\n",
    "N=5 # fix it for other value of N\n",
    "\n",
    "SEP=\" \"\n",
    "\n",
    "sentence_count=5\n",
    "\n",
    "ngrams = build_ngrams()\n",
    "start_seq=None\n",
    "\n",
    "counts = ngram_freqs(ngrams)\n",
    "\n",
    "\n",
    "\n",
    "if start_seq is None: start_seq = random.choice(list(counts.keys()))\n",
    "generated = start_seq.lower();\n",
    "\n",
    "sentences = 0\n",
    "while sentences < sentence_count:\n",
    "    generated += SEP + next_word(generated, N, counts)\n",
    "    sentences += 1 if generated.endswith(('.','!', '?')) else 0\n",
    "\n",
    "# put your code here:\n",
    "\n",
    "print(generated)\n",
    "print()\n",
    "print(clean_generated(generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
